from transformers import AutoTokenizer, AutoModelForCausalLM

model_id = "mistralai/Mistral-7B-Instruct-v0.1"

print("ğŸ”„ ëª¨ë¸ ë¡œë”© ì‹œì‘...")

tokenizer = AutoTokenizer.from_pretrained(model_id)
model = AutoModelForCausalLM.from_pretrained(
    model_id,
    device_map="auto",       # GPU ìë™ í• ë‹¹
    torch_dtype="auto"       # 16bit float ìë™ ì ìš©
)

print("âœ… ëª¨ë¸ ë¡œë”© ì™„ë£Œ!")
